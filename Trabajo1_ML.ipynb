{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ploting support stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn\n",
    "seaborn.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "4\n",
      "[ 4.9  3.   1.4  0.2]\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = iris_data.data.shape\n",
    "print(n_samples)\n",
    "print(n_features)\n",
    "print(iris_data.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.data.shape)\n",
    "print(iris_data.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    def __init__(self, n_clases=None):\n",
    "        if n_clases is None:\n",
    "            self.n_ys   = None;\n",
    "        else:\n",
    "            self.n_ys   = n_clases;\n",
    "            \n",
    "        self.n_features = None;\n",
    "        \n",
    "        self.frec_clase = None;\n",
    "        self.mean       = None;\n",
    "        self.sd         = None;\n",
    "            \n",
    "        self.X          = None;\n",
    "        self.y          = None;\n",
    "\n",
    "    \n",
    "    def frecuencia(self):\n",
    "        for i in self.y :\n",
    "            self.frec_clase[i] += 1; \n",
    "\n",
    "            \n",
    "    def means(self):\n",
    "        accum   = np.zeros((self.n_ys,self.n_features));\n",
    "        \n",
    "        i       = 0;\n",
    "        while i < len(self.y):\n",
    "            j = 0;\n",
    "            while j < self.n_features:\n",
    "                accum[self.y[i]][j]   += self.X[i][j];\n",
    "                j += 1;\n",
    "            i += 1;\n",
    "            \n",
    "        i = 0;\n",
    "        while i < self.n_ys:\n",
    "            j = 0;\n",
    "            while j < self.n_features:\n",
    "                self.mean[i][j] = accum[i][j] / self.frec_clase[i];\n",
    "                j += 1;\n",
    "            i += 1;\n",
    "\n",
    "    def sds(self):\n",
    "        accum   = np.zeros((self.n_ys,self.n_features));\n",
    "        \n",
    "        i       = 0;\n",
    "        while i < len(self.y):\n",
    "            j = 0;\n",
    "            while j < self.n_features:\n",
    "                accum[self.y[i]][j]   += np.power(self.X[i][j] - self.mean[self.y[i]][j], 2);\n",
    "                j += 1;\n",
    "            i += 1;\n",
    "            \n",
    "        i = 0;\n",
    "        while i < self.n_ys:\n",
    "            j = 0;\n",
    "            while j < self.n_features:\n",
    "                self.sd[i][j] = np.sqrt(accum[i][j] / (self.frec_clase[i]-1));\n",
    "                j += 1;\n",
    "            i += 1; \n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        result  = [];\n",
    "        prob_y_x = np.ones(self.n_ys);\n",
    "        \n",
    "        for x in X:\n",
    "            for i in range(self.n_ys):\n",
    "                exp       = np.exp( (np.divide((self.mean[i].transpose() - x) ,self.sd[i])* (self.mean[i]-x))/(-2.0)) ;\n",
    "                prob_x_y  = exp/ (np.power(2*np.pi, self.n_features/2.0) * np.sqrt(np.linalg.norm(self.sd[i])));\n",
    "                prob_y    = self.frec_clase[i]/float(len(self.y));\n",
    "                \n",
    "                prob_y_x[i] = np.prod(prob_x_y) * prob_y;\n",
    "            \n",
    "            result.append(np.argmax(prob_y_x));\n",
    "            \n",
    "        return result;\n",
    "    \n",
    "    def learn(self, X,y):\n",
    "        self.X  = X;\n",
    "        self.y  = y;\n",
    "        \n",
    "        self.n_features = X.shape[1];\n",
    "        \n",
    "        if self.n_ys is None:\n",
    "            self.n_ys = y.max();\n",
    "            \n",
    "        self.frec_clase = np.zeros(self.n_ys);\n",
    "        self.frecuencia();\n",
    "        \n",
    "        self.mean       = np.zeros((self.n_ys,n_features));\n",
    "        self.means();\n",
    "        \n",
    "        self.sd         = np.zeros((self.n_ys,n_features));\n",
    "        self.sds();\n",
    "                \n",
    "    def acc(self, X_test, y_test):\n",
    "        y_values = self.predict(X_test);\n",
    "        count    = 0;\n",
    "        for  i,j in zip(y_test,y_values):\n",
    "            if i == j:\n",
    "                count += 1.0;\n",
    "        return count/len(y_test)*100.0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 95.33333333333334%\n"
     ]
    }
   ],
   "source": [
    "entrenador = NaiveBayes(3);\n",
    "entrenador.learn(iris_data.data, iris_data.target);\n",
    "print(\"Acc: \" + str(entrenador.acc(iris_data.data, iris_data.target)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "class KNN():\n",
    "    def __init__(self, n_clases = None, k = 3):\n",
    "        if n_clases is None:\n",
    "            self.n_ys   = None;\n",
    "        else:\n",
    "            self.n_ys   = n_clases;\n",
    "            \n",
    "        self.k          = k;\n",
    "            \n",
    "        self.X          = None;\n",
    "        self.y          = None;\n",
    "\n",
    "        \n",
    "    def predict(self,X):\n",
    "        result    = [];\n",
    "   \n",
    "        for x in X:\n",
    "            distances = [];\n",
    "            for x_train, y_train in zip(self.X, self.y):\n",
    "                distances.append((distance.euclidean(x, x_train), y_train));\n",
    "            distances = sorted(distances, key=lambda d: d[0]);\n",
    "\n",
    "            \n",
    "            count_k_y = np.zeros(self.n_ys);\n",
    "            for i in range(self.k):\n",
    "                count_k_y[distances[i][1]] += 1;\n",
    "                \n",
    "            result.append(np.argmax(count_k_y));\n",
    "                \n",
    "        return result;\n",
    "            \n",
    "            \n",
    "    \n",
    "    def learn(self, X,y):\n",
    "        self.X  = X;\n",
    "        self.y  = y;\n",
    "\n",
    "        \n",
    "        if self.n_ys is None:\n",
    "            self.n_ys = y.max();        \n",
    "    \n",
    "    def acc(self, X_test, y_test):\n",
    "        y_values = self.predict(X_test);\n",
    "        count    = 0;\n",
    "        for  i,j in zip(y_test,y_values):\n",
    "            if i == j:\n",
    "                count += 1.0;\n",
    "        return count/len(y_test)*100.0;\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 96.0%\n"
     ]
    }
   ],
   "source": [
    "entrenador = KNN(3);\n",
    "entrenador.learn(iris_data.data, iris_data.target);\n",
    "print(\"Acc: \" + str(entrenador.acc(iris_data.data, iris_data.target)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
